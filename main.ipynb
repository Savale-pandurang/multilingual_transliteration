{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2f9c6c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cc6ff0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set the root directory containing all language subfolders\n",
    "DATA_ROOT = \"/multilingual_transliteration/aksharantar_sampled\"\n",
    "SAVE_PATH = \"/multilingual_transliteration/seq2seq_attn_multilingual_best.pt\"\n",
    "\n",
    "SEED = 42\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "random.seed(SEED); torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "ENC_LAYERS = 2\n",
    "DEC_LAYERS = 2\n",
    "ENC_BIDIR = True\n",
    "DROPOUT = 0.2\n",
    "BATCH_SIZE = 256\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NUM_EPOCHS = 20\n",
    "CLIP = 1.0\n",
    "BEAM_SIZE = 5\n",
    "TEACHER_FORCING_START = 0.9\n",
    "TEACHER_FORCING_END = 0.4\n",
    "USE_LANG_TOKEN = True\n",
    "\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print(f\"Google Drive mounted. Checking path: {DATA_ROOT}\")\n",
    "\n",
    "    # Check if the path actually exists after mounting\n",
    "    if not os.path.isdir(DATA_ROOT):\n",
    "        print(f\"WARNING: The directory {DATA_ROOT} does not exist.\")\n",
    "        print(\"Please check your DATA_ROOT path. Common issues:\")\n",
    "        print(\"1. A typo in the path (it's case-sensitive).\")\n",
    "        print(\"2. The folder 'aksharantar_sampled' is not in your 'MyDrive' folder.\")\n",
    "    else:\n",
    "        print(\"Data directory found. Proceeding with loading.\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"Not in Google Colab, assuming local file system. Skipping drive mount.\")\n",
    "    if not os.path.isdir(DATA_ROOT):\n",
    "         print(f\"WARNING: The local directory {DATA_ROOT} does not exist.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fdce9c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ---------- Load & merge all language files ----------\n",
    "\n",
    "def load_and_preprocess_csv(filepath, lang_code):\n",
    "    \"\"\"\n",
    "    Loads a single CSV file (with NO header) and applies preprocessing.\n",
    "    Assumes:\n",
    "    - Column 0: input_text (independent variable)\n",
    "    - Column 1: target_text (dependent variable)\n",
    "    \"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Warning: File not found, skipping: {filepath}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, header=None)\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"Warning: Skipping {filepath}, file is empty.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Failed to read {filepath}. Error: {e}\")\n",
    "        return None\n",
    "\n",
    "    if 0 not in df.columns or 1 not in df.columns:\n",
    "         print(f\"Warning: Skipping {filepath}, expected at least 2 columns, but found {len(df.columns)}.\")\n",
    "         return None\n",
    "\n",
    "    df = df.rename(columns={0: 'input_text', 1: 'target_text'})\n",
    "\n",
    "    if 'input_text' not in df.columns or 'target_text' not in df.columns:\n",
    "        print(f\"Warning: Skipping {filepath}, failed to rename columns.\")\n",
    "        return None\n",
    "\n",
    "    df = df[['input_text','target_text']].astype(str).copy()\n",
    "    df['language'] = lang_code\n",
    "\n",
    "    if USE_LANG_TOKEN:\n",
    "        lang_token = f\"<{lang_code}>\"\n",
    "        df['input_text'] = lang_token + \" \" + df['input_text'].astype(str)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7d79a3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Find all language subdirectories in the DATA_ROOT\n",
    "if not os.path.isdir(DATA_ROOT):\n",
    "    raise FileNotFoundError(f\"Data root directory not found. Please mount Google Drive and check your DATA_ROOT path: {DATA_ROOT}\")\n",
    "\n",
    "lang_codes = [d for d in os.listdir(DATA_ROOT) if os.path.isdir(os.path.join(DATA_ROOT, d))]\n",
    "# lang_codes=lang_codes[:2]\n",
    "print(f\"Found {len(lang_codes)} language folders: {lang_codes}\")\n",
    "\n",
    "train_dfs, valid_dfs, test_dfs = [], [], []\n",
    "\n",
    "# Loop through each language folder and load its train, valid, and test files\n",
    "for lang in tqdm(lang_codes, desc=\"Loading all language data\"):\n",
    "    train_file = os.path.join(DATA_ROOT, lang, f\"{lang}_train.csv\")\n",
    "    valid_file = os.path.join(DATA_ROOT, lang, f\"{lang}_valid.csv\")\n",
    "    test_file  = os.path.join(DATA_ROOT, lang, f\"{lang}_test.csv\")\n",
    "\n",
    "    # Load and append training data\n",
    "    df_train_lang = load_and_preprocess_csv(train_file, lang)\n",
    "    if df_train_lang is not None:\n",
    "        train_dfs.append(df_train_lang)\n",
    "\n",
    "    # Load and append validation data\n",
    "    df_valid_lang = load_and_preprocess_csv(valid_file, lang)\n",
    "    if df_valid_lang is not None:\n",
    "        valid_dfs.append(df_valid_lang)\n",
    "\n",
    "    # Load and append test data\n",
    "    df_test_lang = load_and_preprocess_csv(test_file, lang)\n",
    "    if df_test_lang is not None:\n",
    "        test_dfs.append(df_test_lang)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e067c7f7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Concatenate all dataframes from all languages\n",
    "if not train_dfs or not valid_dfs or not test_dfs:\n",
    "    raise ValueError(\"No data was loaded. Check your DATA_ROOT path and file structure. Did you mount Google Drive?\")\n",
    "\n",
    "train_df = pd.concat(train_dfs, ignore_index=True)\n",
    "valid_df = pd.concat(valid_dfs, ignore_index=True)\n",
    "test_df  = pd.concat(test_dfs, ignore_index=True)\n",
    "\n",
    "print(\"Successfully loaded and merged all language files.\")\n",
    "\n",
    "train_df = train_df.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "print(\"Train size:\", len(train_df), \"Valid size:\", len(valid_df), \"Test size:\", len(test_df))\n",
    "\n",
    "\n",
    "def build_vocab(series):\n",
    "    chars = sorted(set(\"\".join(series.astype(str))))\n",
    "    # Add special tokens (in this order) so indices are predictable\n",
    "    itos = ['<pad>','<sos>','<eos>','<unk>'] + chars\n",
    "    stoi = {c:i for i,c in enumerate(itos)}\n",
    "    return stoi, itos\n",
    "\n",
    "# Build vocab from training set\n",
    "src_stoi, src_itos = build_vocab(train_df['input_text'])\n",
    "tgt_stoi, tgt_itos = build_vocab(train_df['target_text'])\n",
    "\n",
    "SRC_PAD = src_stoi['<pad>']; TGT_PAD = tgt_stoi['<pad>']\n",
    "TGT_SOS = tgt_stoi['<sos>']; TGT_EOS = tgt_stoi['<eos>']\n",
    "\n",
    "print(\"Vocab sizes (src/tgt):\", len(src_itos), len(tgt_itos))\n",
    "print(f\"Sample src token '<asm>': {src_stoi.get('<asm>')}\")\n",
    "print(f\"Sample src token 'a': {src_stoi.get('a')}\")\n",
    "print(f\"Sample tgt token 'a': {tgt_stoi.get('a')}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebefa04b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ---------- Dataset & Collate ----------\n",
    "class TransliterationDataset(Dataset):\n",
    "    def __init__(self, df, src_vocab, tgt_vocab):\n",
    "        self.src_list = df['input_text'].astype(str).tolist()\n",
    "        self.tgt_list = df['target_text'].astype(str).tolist()\n",
    "        self.src_vocab = src_vocab\n",
    "        self.tgt_vocab = tgt_vocab\n",
    "    def __len__(self): return len(self.src_list)\n",
    "    def encode_src(self, s):\n",
    "        return torch.tensor([self.src_vocab.get(ch, self.src_vocab['<unk>']) for ch in s], dtype=torch.long)\n",
    "    def encode_tgt(self, t):\n",
    "        return torch.tensor([self.tgt_vocab.get(ch, self.tgt_vocab['<unk>']) for ch in t], dtype=torch.long)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.encode_src(self.src_list[idx]), self.encode_tgt(self.tgt_list[idx])\n",
    "\n",
    "def collate_fn(batch):\n",
    "    srcs, tgts = zip(*batch)\n",
    "    src_pad = pad_sequence(srcs, batch_first=True, padding_value=SRC_PAD)\n",
    "    tgts_with_tokens = [torch.cat([torch.tensor([TGT_SOS]), t, torch.tensor([TGT_EOS])]) for t in tgts]\n",
    "    tgt_pad = pad_sequence(tgts_with_tokens, batch_first=True, padding_value=TGT_PAD)\n",
    "    src_lens = torch.tensor([len(s) for s in srcs], dtype=torch.long)\n",
    "    tgt_lens = torch.tensor([len(t) for t in tgts_with_tokens], dtype=torch.long)\n",
    "    return src_pad, src_lens, tgt_pad, tgt_lens\n",
    "\n",
    "train_loader = DataLoader(TransliterationDataset(train_df, src_stoi, tgt_stoi), batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(TransliterationDataset(valid_df, src_stoi, tgt_stoi), batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader  = DataLoader(TransliterationDataset(test_df, src_stoi, tgt_stoi), batch_size=512, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ced306c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ---------- Model ----------\n",
    "def make_rnn(cell, emb_dim, hid_dim, layers, bidir=False, dropout=0.0):\n",
    "    if cell == \"lstm\":\n",
    "        return nn.LSTM(emb_dim, hid_dim, num_layers=layers, batch_first=True, bidirectional=bidir, dropout=dropout if layers>1 else 0)\n",
    "    elif cell == \"gru\":\n",
    "        return nn.GRU(emb_dim, hid_dim, num_layers=layers, batch_first=True, bidirectional=bidir, dropout=dropout if layers>1 else 0)\n",
    "    else:\n",
    "        return nn.RNN(emb_dim, hid_dim, num_layers=layers, batch_first=True, nonlinearity='tanh', dropout=dropout if layers>1 else 0)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, bidir=True, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx=SRC_PAD)\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.bidir = bidir\n",
    "        self.rnn = make_rnn(\"lstm\", emb_dim, hid_dim, n_layers, bidir, dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, src):\n",
    "        emb = self.dropout(self.embedding(src))\n",
    "        outputs, (h_n, c_n) = self.rnn(emb)\n",
    "        return outputs, (h_n, c_n)\n",
    "\n",
    "class LuongAttention(nn.Module):\n",
    "    def __init__(self, hid_dim, bidirectional_encoder=True):\n",
    "        super().__init__()\n",
    "        enc_mult = 2 if bidirectional_encoder else 1\n",
    "        self.Wa = nn.Linear(hid_dim, hid_dim * enc_mult, bias=False)\n",
    "    def forward(self, dec_hidden, enc_outputs, mask):\n",
    "        proj = self.Wa(dec_hidden)\n",
    "        proj = proj.unsqueeze(1)\n",
    "        scores = torch.bmm(proj, enc_outputs.transpose(1,2)).squeeze(1)\n",
    "        scores = scores.masked_fill(mask==0, -1e9)\n",
    "        attn = torch.softmax(scores, dim=1)\n",
    "        context = torch.bmm(attn.unsqueeze(1), enc_outputs).squeeze(1)\n",
    "        return context, attn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08fb36f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class DecoderWithAttention(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, enc_bidirectional=True, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim, padding_idx=TGT_PAD)\n",
    "        enc_mult = 2 if enc_bidirectional else 1\n",
    "        self.rnn = nn.LSTM(emb_dim + hid_dim * enc_mult, hid_dim, num_layers=n_layers, batch_first=True, dropout=dropout if n_layers>1 else 0)\n",
    "        self.attn = LuongAttention(hid_dim, bidirectional_encoder=enc_bidirectional)\n",
    "        self.fc_out = nn.Linear(hid_dim + hid_dim * enc_mult + emb_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.hid_dim = hid_dim\n",
    "    def forward(self, input_tok, last_hidden, last_cell, enc_outputs, mask):\n",
    "        emb = self.dropout(self.embedding(input_tok))     \n",
    "        dec_h_top = last_hidden[-1]                         \n",
    "        context, attn = self.attn(dec_h_top, enc_outputs, mask)  \n",
    "        rnn_input = torch.cat([emb, context.unsqueeze(1)], dim=2)  \n",
    "        output, (h_n, c_n) = self.rnn(rnn_input, (last_hidden, last_cell))\n",
    "        output = output.squeeze(1)                       \n",
    "        fc_in = torch.cat([output, context, emb.squeeze(1)], dim=1)  \n",
    "        prediction = self.fc_out(fc_in)                   \n",
    "        return prediction, h_n, c_n, attn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55762e4f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class Bridge(nn.Module):\n",
    "    def __init__(self, enc_layers, dec_layers, enc_hid, dec_hid, bidirectional=True):\n",
    "        super().__init__()\n",
    "        self.enc_layers = enc_layers\n",
    "        self.dec_layers = dec_layers\n",
    "        self.bid = bidirectional\n",
    "        enc_mult = 2 if bidirectional else 1\n",
    "        self.hid_map = nn.Linear(enc_hid * enc_mult, dec_hid)\n",
    "        self.cell_map = nn.Linear(enc_hid * enc_mult, dec_hid)\n",
    "    def forward(self, h_enc, c_enc):\n",
    "        enc_layers = self.enc_layers\n",
    "        enc_mult = 2 if self.bid else 1\n",
    "        B = h_enc.size(1)\n",
    "        h_enc = h_enc.view(enc_layers, enc_mult, B, -1)\n",
    "        c_enc = c_enc.view(enc_layers, enc_mult, B, -1)\n",
    "        h_cat = h_enc.view(enc_layers, B, -1)\n",
    "        c_cat = c_enc.view(enc_layers, B, -1)\n",
    "        h_list = []\n",
    "        c_list = []\n",
    "        for i in range(self.dec_layers):\n",
    "            idx = min(i, enc_layers-1)\n",
    "            h_proj = torch.tanh(self.hid_map(h_cat[idx]))\n",
    "            c_proj = torch.tanh(self.cell_map(c_cat[idx]))\n",
    "            h_list.append(h_proj.unsqueeze(0))\n",
    "            c_list.append(c_proj.unsqueeze(0))\n",
    "        h_dec = torch.cat(h_list, dim=0)\n",
    "        c_dec = torch.cat(c_list, dim=0)\n",
    "        return h_dec, c_dec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8419ed8b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Instantiate models\n",
    "enc = Encoder(len(src_itos), EMB_DIM, HID_DIM, ENC_LAYERS, bidir=ENC_BIDIR, dropout=DROPOUT).to(DEVICE)\n",
    "dec = DecoderWithAttention(len(tgt_itos), EMB_DIM, HID_DIM, DEC_LAYERS, enc_bidirectional=ENC_BIDIR, dropout=DROPOUT).to(DEVICE)\n",
    "bridge = Bridge(ENC_LAYERS, DEC_LAYERS, HID_DIM, HID_DIM, bidirectional=ENC_BIDIR).to(DEVICE)\n",
    "\n",
    "def count_params(*mods):\n",
    "    return sum(p.numel() for m in mods for p in m.parameters() if p.requires_grad)\n",
    "print(\"Trainable params:\", count_params(enc, dec, bridge))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852ec0c8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ---------- Training & Eval (unchanged logic) ----------\n",
    "def make_mask(src_pad):\n",
    "    return (src_pad != SRC_PAD).to(DEVICE)\n",
    "\n",
    "def train_epoch(model_components, loader, optimizer, epoch):\n",
    "    enc, dec, bridge = model_components\n",
    "    enc.train(); dec.train(); bridge.train()\n",
    "    total_loss = 0\n",
    "    n_batches = 0\n",
    "    tf_ratio = TEACHER_FORCING_START + (TEACHER_FORCING_END - TEACHER_FORCING_START) * (epoch / max(1, NUM_EPOCHS-1))\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=TGT_PAD)\n",
    "    for src, src_lens, tgt, tgt_lens in tqdm(loader, desc=f\"Train E{epoch}\"):\n",
    "        src = src.to(DEVICE); tgt = tgt.to(DEVICE)\n",
    "        mask = make_mask(src)\n",
    "        optimizer.zero_grad()\n",
    "        enc_outputs, (h_n, c_n) = enc(src)\n",
    "        h_dec, c_dec = bridge(h_n, c_n)\n",
    "        max_tgt_len = tgt.size(1)\n",
    "        input_tok = tgt[:,0].unsqueeze(1)\n",
    "        losses = []\n",
    "        for t in range(1, max_tgt_len):\n",
    "            pred, h_dec, c_dec, attn = dec(input_tok, h_dec, c_dec, enc_outputs, mask)\n",
    "            target = tgt[:,t]\n",
    "            losses.append(criterion(pred, target))\n",
    "            teacher_force = random.random() < tf_ratio\n",
    "            top1 = pred.argmax(1).unsqueeze(1)\n",
    "            input_tok = tgt[:,t].unsqueeze(1) if teacher_force else top1\n",
    "        loss = torch.stack(losses).mean()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(list(enc.parameters()) + list(dec.parameters()) + list(bridge.parameters()), CLIP)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        n_batches += 1\n",
    "    return total_loss / max(1, n_batches)\n",
    "\n",
    "def evaluate_components(model_components, loader):\n",
    "    enc, dec, bridge = model_components\n",
    "    enc.eval(); dec.eval(); bridge.eval()\n",
    "    total_loss = 0.0; n_batches = 0\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=TGT_PAD)\n",
    "    with torch.no_grad():\n",
    "        for src, src_lens, tgt, tgt_lens in tqdm(loader, desc=\"Valid\"):\n",
    "            src = src.to(DEVICE); tgt = tgt.to(DEVICE)\n",
    "            mask = make_mask(src)\n",
    "            enc_outputs, (h_n, c_n) = enc(src)\n",
    "            h_dec, c_dec = bridge(h_n, c_n)\n",
    "            input_tok = tgt[:,0].unsqueeze(1)\n",
    "            losses = []\n",
    "            for t in range(1, tgt.size(1)):\n",
    "                pred, h_dec, c_dec, attn = dec(input_tok, h_dec, c_dec, enc_outputs, mask)\n",
    "                target = tgt[:,t]\n",
    "                losses.append(criterion(pred, target))\n",
    "                input_tok = pred.argmax(1).unsqueeze(1)\n",
    "            if losses:\n",
    "                loss = torch.stack(losses).mean()\n",
    "                total_loss += loss.item(); n_batches += 1\n",
    "    return total_loss / max(1, n_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c003f46e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Beam search decode (char-level)\n",
    "def beam_search_decode(enc, dec, bridge, src_sentence, beam_size=BEAM_SIZE, max_len=80):\n",
    "    enc.eval(); dec.eval(); bridge.eval()\n",
    "    with torch.no_grad():\n",
    "        src_idx = torch.tensor([[src_stoi.get(c, src_stoi['<unk>']) for c in src_sentence]]).to(DEVICE)\n",
    "        enc_outputs, (h_n, c_n) = enc(src_idx)\n",
    "        mask = (src_idx != SRC_PAD).to(DEVICE)\n",
    "        h_dec, c_dec = bridge(h_n, c_n)\n",
    "        init = ([TGT_SOS], 0.0, h_dec, c_dec)\n",
    "        beam = [init]\n",
    "        completed = []\n",
    "        for _ in range(max_len):\n",
    "            new_beam = []\n",
    "            for tokens, logp, h_cur, c_cur in beam:\n",
    "                if tokens[-1] == TGT_EOS:\n",
    "                    completed.append((tokens, logp))\n",
    "                    continue\n",
    "                input_tok = torch.tensor([[tokens[-1]]], device=DEVICE)\n",
    "                pred, h_new, c_new, attn = dec(input_tok, h_cur, c_cur, enc_outputs, mask)\n",
    "                log_probs = torch.log_softmax(pred, dim=1).squeeze(0)\n",
    "                topk_logp, topk_idx = torch.topk(log_probs, beam_size)\n",
    "                for l, idx in zip(topk_logp.tolist(), topk_idx.tolist()):\n",
    "                    new_tokens = tokens + [idx]\n",
    "                    new_logp = logp + l\n",
    "                    new_beam.append((new_tokens, new_logp, h_new, c_new))\n",
    "            beam = sorted(new_beam, key=lambda x: x[1], reverse=True)[:beam_size]\n",
    "            if not beam:\n",
    "                break\n",
    "        candidates = completed + beam\n",
    "        if not candidates:\n",
    "             return \"\" # Handle empty candidates\n",
    "        candidates = sorted(candidates, key=lambda x: x[1], reverse=True)\n",
    "        best_tokens = candidates[0][0]\n",
    "        toks = []\n",
    "        for t in best_tokens:\n",
    "            if t == TGT_SOS: continue\n",
    "            if t == TGT_EOS: break\n",
    "            toks.append(tgt_itos[t])\n",
    "        return \"\".join(toks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c527136",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ---------- Run training ----------\n",
    "optimizer = torch.optim.Adam(list(enc.parameters()) + list(dec.parameters()) + list(bridge.parameters()), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience = 4\n",
    "no_improve = 0\n",
    "\n",
    "print(\"\\n--- Starting Training ---\")\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    start = time.time()\n",
    "    train_loss = train_epoch((enc, dec, bridge), train_loader, optimizer, epoch)\n",
    "    val_loss = evaluate_components((enc, dec, bridge), valid_loader)\n",
    "    scheduler.step(val_loss)\n",
    "    elapsed = time.time() - start\n",
    "    print(f\"Epoch {epoch}: Train loss {train_loss:.4f}, Val loss {val_loss:.4f}, time {elapsed:.1f}s\")\n",
    "    if val_loss < best_val_loss - 1e-4:\n",
    "        best_val_loss = val_loss\n",
    "        no_improve = 0\n",
    "        torch.save({\n",
    "            'enc': enc.state_dict(),\n",
    "            'dec': dec.state_dict(),\n",
    "            'bridge': bridge.state_dict(),\n",
    "            'src_itos': src_itos, 'src_stoi': src_stoi,\n",
    "            'tgt_itos': tgt_itos, 'tgt_stoi': tgt_stoi\n",
    "        }, SAVE_PATH)\n",
    "        print(f\"Saved best checkpoint to {SAVE_PATH}\")\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        print(f\"No improvement {no_improve}/{patience}\")\n",
    "        if no_improve >= patience:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n",
    "print(\"--- Training Finished ---\")\n",
    "\n",
    "# ---------- Inference & Evaluation ----------\n",
    "print(f\"\\n--- Loading best model for evaluation ---\")\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    print(\"Error: Saved model not found. Skipping evaluation.\")\n",
    "    # Set examples to reflect codes, but exit gracefully\n",
    "    examples = [\"<tam> namaskaram\", \"<hin> pani\", \"<ben> prem\"]\n",
    "    print(\"\\nExamples (ensure language codes match folder names):\")\n",
    "    for w in examples:\n",
    "        print(w, \"->\", \"(Model not trained or loaded)\")\n",
    "else:\n",
    "    ckpt = torch.load(SAVE_PATH, map_location=DEVICE)\n",
    "    enc.load_state_dict(ckpt['enc'])\n",
    "    dec.load_state_dict(ckpt['dec'])\n",
    "    bridge.load_state_dict(ckpt['bridge'])\n",
    "    # Ensure vocabs are loaded from checkpoint for consistency\n",
    "    src_stoi = ckpt['src_stoi']\n",
    "    src_itos = ckpt['src_itos']\n",
    "    tgt_stoi = ckpt['tgt_stoi']\n",
    "    tgt_itos = ckpt['tgt_itos']\n",
    "\n",
    "    enc.to(DEVICE); dec.to(DEVICE); bridge.to(DEVICE)\n",
    "    print(\"Model loaded successfully.\")\n",
    "\n",
    "    # Evaluate on test using beam search\n",
    "    def levenshtein(a, b):\n",
    "        n, m = len(a), len(b)\n",
    "        if n == 0: return m\n",
    "        if m == 0: return n\n",
    "        dp = list(range(m+1))\n",
    "        for i in range(1, n+1):\n",
    "            prev = dp[0]\n",
    "            dp[0] = i\n",
    "            for j in range(1, m+1):\n",
    "                cur = dp[j]\n",
    "                if a[i-1] == b[j-1]:\n",
    "                    dp[j] = prev\n",
    "                else:\n",
    "                    dp[j] = 1 + min(prev, dp[j], dp[j-1])\n",
    "                prev = cur\n",
    "        return dp[m]\n",
    "\n",
    "    total_chars = 0\n",
    "    correct_chars = 0\n",
    "    total_edits = 0\n",
    "    total_ref_chars = 0\n",
    "\n",
    "    # Store some examples\n",
    "    results_df = []\n",
    "\n",
    "    for i in tqdm(range(len(test_df)), desc=\"Test eval\"):\n",
    "        src = test_df.iloc[i]['input_text']\n",
    "        ref = test_df.iloc[i]['target_text']\n",
    "        pred = beam_search_decode(enc, dec, bridge, src, beam_size=BEAM_SIZE, max_len=80)\n",
    "\n",
    "        if i < 10: # Store first 10 examples\n",
    "             results_df.append({'Source': src, 'Reference': ref, 'Prediction': pred})\n",
    "\n",
    "        L = min(len(pred), len(ref))\n",
    "        correct_chars += sum(pred[j]==ref[j] for j in range(L))\n",
    "        total_chars += L\n",
    "        total_edits += levenshtein(pred, ref)\n",
    "        total_ref_chars += len(ref)\n",
    "\n",
    "    # Calculate Character Accuracy (based on min length)\n",
    "    char_acc = correct_chars / total_chars if total_chars>0 else 0.0\n",
    "\n",
    "    # Calculate Character Error Rate (CER)\n",
    "    cer = total_edits / total_ref_chars if total_ref_chars>0 else None\n",
    "\n",
    "    # Calculate Word Accuracy (Exact Match)\n",
    "    exact_matches = 0\n",
    "    for i in tqdm(range(len(test_df)), desc=\"Word Accuracy\"):\n",
    "        src = test_df.iloc[i]['input_text']\n",
    "        ref = test_df.iloc[i]['target_text']\n",
    "        pred = beam_search_decode(enc, dec, bridge, src, beam_size=BEAM_SIZE, max_len=80)\n",
    "        if pred == ref:\n",
    "            exact_matches += 1\n",
    "\n",
    "    word_acc = exact_matches / len(test_df) if len(test_df) > 0 else 0.0\n",
    "\n",
    "    print(f\"\\n--- Test Set Metrics ---\")\n",
    "    print(f\"Word Accuracy (Exact Match): {word_acc:.4f} ({exact_matches}/{len(test_df)})\")\n",
    "    print(f\"Character Error Rate (CER):  {cer:.4f}\")\n",
    "    print(f\"Character Accuracy (approx): {char_acc:.4f}\")\n",
    "\n",
    "    print(\"\\n--- Test Examples (from test set) ---\")\n",
    "    print(pd.DataFrame(results_df).to_string())\n",
    "\n",
    "    # MODIFIED: Quick examples (use lang codes from folders, e.g., 'tam', 'hin', 'ben')\n",
    "    examples = [\"<tam> namaskaram\", \"<hin> pani\", \"<ben> prem\", \"<asm> val\"]\n",
    "    print(\"\\n--- Custom Examples (beam) ---\")\n",
    "    for w in examples:\n",
    "        if not all(c in src_stoi for c in w):\n",
    "            print(f\"{w} -> (Skipped: contains chars not in training vocab)\")\n",
    "            continue\n",
    "        print(w, \"->\", beam_search_decode(enc, dec, bridge, w, beam_size=BEAM_SIZE))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
